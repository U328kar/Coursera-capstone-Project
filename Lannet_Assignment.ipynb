{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lannet Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/U328kar/Coursera-capstone-Project/blob/master/Lannet_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O2eWFz-ofSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@markdown PROJECT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6W68SW4pAto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcOsqop8pD6S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "6fb9c7d9-f378-403d-db9d-ae692913092b"
      },
      "source": [
        "df = pd.read_excel(r'Dummy.xlsx')\n",
        "df.head(10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SR NO</th>\n",
              "      <th>NAME</th>\n",
              "      <th>Date of Birth</th>\n",
              "      <th>Date of Joining</th>\n",
              "      <th>Date of Resigning</th>\n",
              "      <th>Address</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Akash</td>\n",
              "      <td>1996-02-17</td>\n",
              "      <td>2020-01-01 00:00:00</td>\n",
              "      <td>2025-10-10</td>\n",
              "      <td>New Jersey-123456789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Astha</td>\n",
              "      <td>1998-05-18</td>\n",
              "      <td>2019-12-07 00:00:00</td>\n",
              "      <td>2020-12-12</td>\n",
              "      <td>New York 123456789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Ayush</td>\n",
              "      <td>1999-02-17</td>\n",
              "      <td>2019-08-07 00:00:00</td>\n",
              "      <td>2020-05-13</td>\n",
              "      <td>California-123456789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Ankita</td>\n",
              "      <td>1999-01-20</td>\n",
              "      <td>24/07/2019</td>\n",
              "      <td>2025-12-20</td>\n",
              "      <td>Rome-987654321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Ashwin</td>\n",
              "      <td>1997-03-20</td>\n",
              "      <td>21/08/2019</td>\n",
              "      <td>2024-12-20</td>\n",
              "      <td>Madrid 123456178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>Amit</td>\n",
              "      <td>1900-01-02</td>\n",
              "      <td>2020-12-03 00:00:00</td>\n",
              "      <td>2023-10-19</td>\n",
              "      <td>Malmo ff 435612789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>Arastu</td>\n",
              "      <td>1997-07-17</td>\n",
              "      <td>15/03/2020</td>\n",
              "      <td>2022-10-18</td>\n",
              "      <td>Amsterdam 12907856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>Ojasvi</td>\n",
              "      <td>1998-08-18</td>\n",
              "      <td>2018-07-20 00:00:00</td>\n",
              "      <td>2022-10-19</td>\n",
              "      <td>Gnoida 203040506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>Utkrsh</td>\n",
              "      <td>1999-02-20</td>\n",
              "      <td>2020-07-20 00:00:00</td>\n",
              "      <td>2029-12-20</td>\n",
              "      <td>Delhi 110092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>Utkarsh</td>\n",
              "      <td>1999-02-20</td>\n",
              "      <td>2020-07-20 00:00:00</td>\n",
              "      <td>2029-12-20</td>\n",
              "      <td>Delhi 110092</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SR NO     NAME  ... Date of Resigning                Address\n",
              "0      1    Akash  ...        2025-10-10   New Jersey-123456789\n",
              "1      2    Astha  ...        2020-12-12     New York 123456789\n",
              "2      3    Ayush  ...        2020-05-13   California-123456789\n",
              "3      4   Ankita  ...        2025-12-20         Rome-987654321\n",
              "4      5   Ashwin  ...        2024-12-20       Madrid 123456178\n",
              "5      6     Amit  ...        2023-10-19     Malmo ff 435612789\n",
              "6      7   Arastu  ...        2022-10-18     Amsterdam 12907856\n",
              "7      8   Ojasvi  ...        2022-10-19       Gnoida 203040506\n",
              "8      9   Utkrsh  ...        2029-12-20           Delhi 110092\n",
              "9     10  Utkarsh  ...        2029-12-20           Delhi 110092\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHc74eHlp5ZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#NOw Q1.1) -Write a function in python that identify which columns have date in them"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxGQ7reDsJKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object':\n",
        "        try:\n",
        "            df[col] = pd.to_datetime(df[col])\n",
        "        except ValueError:\n",
        "            pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJM8wl8UsXpy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "88bb8cc0-63ff-4e1a-dd48-4271bb359522"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SR NO                         int64\n",
              "NAME                         object\n",
              "Date of Birth        datetime64[ns]\n",
              "Date of Joining      datetime64[ns]\n",
              "Date of Resigning    datetime64[ns]\n",
              "Address                      object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHPtbE4Os5uG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Q1.2) Using these date columns make new columns which are difference between these columns taking 2 at a time\n",
        "# Q1.3) Drop all the original columns containing the date and just keep the newly computed columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1qMNDv0sab7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def date_diff(dataframe):\n",
        "    a=pd.DataFrame\n",
        "    for col in dataframe.columns:\n",
        "        if dataframe[col].dtype == 'object':\n",
        "            try:\n",
        "                dataframe[col] = pd.to_datetime(dataframe[col])\n",
        "            except ValueError:\n",
        "                pass\n",
        "    a=dataframe.select_dtypes('datetime64[ns]')\n",
        "    drop_col=a.columns\n",
        "    b=0\n",
        "    c=pd.DataFrame()\n",
        "    for i in range(0,len(a.columns)):\n",
        "        b+=1\n",
        "        for j in range(b,len(a.columns)):\n",
        "            c=c.append(a.iloc[:,i]-a.iloc[:,j],ignore_index=True)\n",
        "    dataframe=dataframe.drop(columns=drop_col)\n",
        "    a=c.T\n",
        "    dataframe=pd.concat([dataframe,a],axis=1, sort=False)\n",
        "    return dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7se4ewJHsw5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=date_diff(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qdIuw7gs0f8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "53a361ce-24ce-4765-a261-25f197815a4e"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SR NO</th>\n",
              "      <th>NAME</th>\n",
              "      <th>Address</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Akash</td>\n",
              "      <td>New Jersey-123456789</td>\n",
              "      <td>-8719 days</td>\n",
              "      <td>-10828 days</td>\n",
              "      <td>-2109 days</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Astha</td>\n",
              "      <td>New York 123456789</td>\n",
              "      <td>-7873 days</td>\n",
              "      <td>-8244 days</td>\n",
              "      <td>-371 days</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Ayush</td>\n",
              "      <td>California-123456789</td>\n",
              "      <td>-7476 days</td>\n",
              "      <td>-7756 days</td>\n",
              "      <td>-280 days</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Ankita</td>\n",
              "      <td>Rome-987654321</td>\n",
              "      <td>-7490 days</td>\n",
              "      <td>-9831 days</td>\n",
              "      <td>-2341 days</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Ashwin</td>\n",
              "      <td>Madrid 123456178</td>\n",
              "      <td>-8189 days</td>\n",
              "      <td>-10137 days</td>\n",
              "      <td>-1948 days</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SR NO    NAME                Address          0           1          2\n",
              "0      1   Akash   New Jersey-123456789 -8719 days -10828 days -2109 days\n",
              "1      2   Astha     New York 123456789 -7873 days  -8244 days  -371 days\n",
              "2      3   Ayush   California-123456789 -7476 days  -7756 days  -280 days\n",
              "3      4  Ankita         Rome-987654321 -7490 days  -9831 days -2341 days\n",
              "4      5  Ashwin       Madrid 123456178 -8189 days -10137 days -1948 days"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J2x5Vj3s3FZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Q2.1) Write a function in python that drop columns having Pearson correlation more than 0.85"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwP93LWbuCJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corr_matrix = df.corr().abs()\n",
        "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
        "to_drop = [column for column in upper.columns if any(upper[column] > 0.85)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tWY580guS7j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "c5a111f6-928b-4fc4-82f7-fb1d991269f2"
      },
      "source": [
        "df.drop(df[to_drop], axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SR NO</th>\n",
              "      <th>NAME</th>\n",
              "      <th>Address</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Akash</td>\n",
              "      <td>New Jersey-123456789</td>\n",
              "      <td>-8719 days</td>\n",
              "      <td>-10828 days</td>\n",
              "      <td>-2109 days</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Astha</td>\n",
              "      <td>New York 123456789</td>\n",
              "      <td>-7873 days</td>\n",
              "      <td>-8244 days</td>\n",
              "      <td>-371 days</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Ayush</td>\n",
              "      <td>California-123456789</td>\n",
              "      <td>-7476 days</td>\n",
              "      <td>-7756 days</td>\n",
              "      <td>-280 days</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Ankita</td>\n",
              "      <td>Rome-987654321</td>\n",
              "      <td>-7490 days</td>\n",
              "      <td>-9831 days</td>\n",
              "      <td>-2341 days</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Ashwin</td>\n",
              "      <td>Madrid 123456178</td>\n",
              "      <td>-8189 days</td>\n",
              "      <td>-10137 days</td>\n",
              "      <td>-1948 days</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>Amit</td>\n",
              "      <td>Malmo ff 435612789</td>\n",
              "      <td>-44165 days</td>\n",
              "      <td>-45215 days</td>\n",
              "      <td>-1050 days</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>Arastu</td>\n",
              "      <td>Amsterdam 12907856</td>\n",
              "      <td>-8277 days</td>\n",
              "      <td>-9224 days</td>\n",
              "      <td>-947 days</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>Ojasvi</td>\n",
              "      <td>Gnoida 203040506</td>\n",
              "      <td>-7276 days</td>\n",
              "      <td>-8828 days</td>\n",
              "      <td>-1552 days</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>Utkrsh</td>\n",
              "      <td>Delhi 110092</td>\n",
              "      <td>-7821 days</td>\n",
              "      <td>-11261 days</td>\n",
              "      <td>-3440 days</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>Utkarsh</td>\n",
              "      <td>Delhi 110092</td>\n",
              "      <td>-7821 days</td>\n",
              "      <td>-11261 days</td>\n",
              "      <td>-3440 days</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SR NO     NAME                Address           0           1          2\n",
              "0      1    Akash   New Jersey-123456789  -8719 days -10828 days -2109 days\n",
              "1      2    Astha     New York 123456789  -7873 days  -8244 days  -371 days\n",
              "2      3    Ayush   California-123456789  -7476 days  -7756 days  -280 days\n",
              "3      4   Ankita         Rome-987654321  -7490 days  -9831 days -2341 days\n",
              "4      5   Ashwin       Madrid 123456178  -8189 days -10137 days -1948 days\n",
              "5      6     Amit     Malmo ff 435612789 -44165 days -45215 days -1050 days\n",
              "6      7   Arastu     Amsterdam 12907856  -8277 days  -9224 days  -947 days\n",
              "7      8   Ojasvi       Gnoida 203040506  -7276 days  -8828 days -1552 days\n",
              "8      9   Utkrsh           Delhi 110092  -7821 days -11261 days -3440 days\n",
              "9     10  Utkarsh           Delhi 110092  -7821 days -11261 days -3440 days"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-VUQVZIuVoH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a913ce2-4e17-40f7-f06a-bd5e558dc01d"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['SR NO', 'NAME', 'Address', 0, 1, 2], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQ1bjU7Nuwkg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Q3.1) Write an explanation about how operations like imputation does, feature selection, normalization etc. changes across the training and the testing data. For example, do you do imputation separately for training and testing set…?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGf1WoTavCNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Explanation about how operations like 1) imputation      2) feature selection   3)Normalization\n",
        "\n",
        "#    1) Imputation is the process of replacing missing data with substituted values. When substituting for a data point, it is known as \"unit imputation\"; when substituting for a component of a data point, it is known as \"item imputation\".\n",
        "# Imputaion is the division between training and test set is an attempt to replicate the situation where we have past information and are building a model which we will test on future as-yet unknown information,the training set takes the place of the past and the test set takes the place of the future, so we only get to test our trained model once.\n",
        "# Keeping the past/future analogy in mind, this means anything we do to pre-process or process our data, such as imputing missing values, we should do on the training set alone. We can then remember what we did to our training set if our test set also needs pre-processing or imputing, so that we do it the same way on both sets.\n",
        "#    2) Feature selection, also known as variable selection, attribute selection or variable subset selection, is the process of selecting a subset of relevant features for use in model construction. \n",
        "# Feature Selection,it is clear that feature selection (FS) have to be done separately on training and then on test data to avoid overly optimistic results.\n",
        "# Feature Selection is the process where you automatically or manually select those features which contribute most to your prediction variable or output in which you are interested in. Having irrelevant features in your data can decrease the accuracy of the models and make your model learn based on irrelevant features.\n",
        "#    3) Normalization,we need to apply normalisation to test data, if our algorithm works with or needs normalised training data*.\n",
        "# That is because our model works on the representation given by its input vectors. The scale of those numbers is part of the representation. This is a bit like converting between feet and metres . . . a model or formula would work with just one type of unit normally.\n",
        "# Not only do we need normalisation, but we should apply the exact same scaling as for our training data. That means storing the scale and offset used with our training data, and using that again. A common beginner mistake is to separately normalise your train and test data.\n",
        "# Yes,Imputation should be done seperately for Training and Testing Phase. Keeping the past/future analogy in mind.\n",
        "# Operations like Imputation,feature selection,normalization does change accross Training and Testing Data."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBGkDj3_1V35",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Q4.1) How to you speed up a python code?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0jQ6OOh1dDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1) Local variables are faster than global variables.So we should use local variables more to speed up python code.\n",
        "#2) simply put the scripting statements in a function.\n",
        "#3) Reducing Memory Footprint.\n",
        "#4) Using the built In Functions and Libraries.\n",
        "#5) Data Structures basics is really important for speeding up the code. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYmbpYmUNncj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  # Q5.1) Write a python function that extract zip code from an address column."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxNZJGd_22OP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df3=pd.read_excel('Dummy2.xlsx')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekV1Exh_3DdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "address=df3.apply(lambda row: row.astype(str).str.contains('^\\d+\\s[A-z]+\\s[A-z]+').any(), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1DF0W_O3ImE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "28d217c7-bb8a-4f30-8afa-c14d2e7a22a9"
      },
      "source": [
        "address\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "address            True\n",
              "Unnamed: 1        False\n",
              "name              False\n",
              "payment_option    False\n",
              "mobile            False\n",
              "srno              False\n",
              "website           False\n",
              "Unnamed: 7        False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DESHIjuT3K_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "df3['zip'] = df3['address'].str.extract(r'([0-9]{5})-?(?!.*[0-9]{5}-?)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InkjtPG0AIEf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "d33d5846-0259-43f0-9149-a1a751b37f8e"
      },
      "source": [
        "df3[\"zip\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      55437\n",
              "1      55437\n",
              "2      55437\n",
              "3      55437\n",
              "4      55437\n",
              "       ...  \n",
              "132    55439\n",
              "133    55439\n",
              "134    55439\n",
              "135    55439\n",
              "136    55439\n",
              "Name: zip, Length: 137, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Tyb5dMTU-Am",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Q6.1) Write a python function to address typos in a column"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gmnx19m0YXM3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#According to me we will have to introduce a dictionary for every dataset from which the function or python can address the typos without which I do not know how to address the Typos.\n",
        "#And If I am wrong please correct me and let me know how this part of the asssignment can be done."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fqKZbHIBewb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "43a4db9e-2972-4b6e-eb6b-79fef225a0c7"
      },
      "source": [
        "pip install pyspellchecker"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspellchecker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/d1/ec4e830e9f9c1fd788e1459dd09279fdf807bc7a475579fd7192450b879c/pyspellchecker-0.5.4-py2.py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 2.7MB/s \n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.5.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WZjW3_-Kbk1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spellchecker import spellchecker"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuEHHV6LYpkF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The main problem according to me will be that to know about what is correct and what is incorrect so for that purpose we will check all the other values if all are same then we can use dictionaries to find the correct one of the two but dictionaries will be different for all the different datasets.\n",
        "#thank you  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}